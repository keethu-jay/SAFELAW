# import uvicorn
# import os
# from fastapi import FastAPI, UploadFile, File, HTTPException, Form
# from fastapi.middleware.cors import CORSMiddleware
# from supabase import create_client, Client

# # --- CONFIGURATION ---
# SUPABASE_URL = os.getenv("SUPABASE_URL")
# SUPABASE_KEY = os.getenv("SUPABASE_KEY")
# supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
#
# # TODO: Initialize your ML Models here
# # embedding_model = ...
# # summarizer_pipeline = ...
#
# app = FastAPI()
#
# # Setup CORS
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"], # Update with your frontend URL in production
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
#
# # --- ENDPOINT 1: READER (Summarization + Logging) ---
# @app.post("/api/summarize")
# async def summarize_document(
#         file: UploadFile = File(...),
#         user_id: str = Form(...) # We need to know WHO is asking
# ):
#     try:
#         # 1. Parse File (TODO: Add PDF/Text parsing logic)
#         text_content = "Parsed text from document..."
#
#         # 2. Run Summarization (TODO: Call your GP-TSM pipeline)
#         # summary = pipeline.run(text_content)
#         final_summary = "Placeholder summary generated by AI..."
#
#         # 3. LOGGING (The Schema Logic)
#         # We verify who the user is and save the result
#         log_entry = {
#             "user_id": user_id,
#             "original_text_chunk": text_content[:2000], # Store first 2k chars for context
#             "generated_summary": final_summary
#             # 'created_at' and 'id' are auto-generated by Supabase
#         }
#
#         # Insert into the 'summarization_logs' table
#         supabase.table("summarization_logs").insert(log_entry).execute()
#
#         return {"summary": final_summary}
#
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))
#
# # --- ENDPOINT 2: WRITER (Semantic Search) ---
# @app.post("/api/search")
# async def semantic_search(query: str = Form(...)):
#     # 1. Embed Query (TODO: Call Voyage AI)
#     # vector = model.embed(query)
#
#     # 2. Search DB (TODO: Call Supabase RPC)
#     # results = supabase.rpc("match_opinions", {"query_embedding": vector}).execute()
#
#     return {"results": []}
#
# if __name__ == "__main__":
#     uvicorn.run(app, host="0.0.0.0", port=8000)